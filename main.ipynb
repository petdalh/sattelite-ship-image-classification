{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images found: 4000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Path to your image directory\n",
    "image_dir = './data/shipsnet/shipsnet/'\n",
    "\n",
    "# List all PNG images in the directory\n",
    "image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.png')]\n",
    "print(\"Total images found:\", len(image_files))\n",
    "\n",
    "\n",
    "# Process and normalize images\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for image_path in image_files:\n",
    "    # Extract label from filename (\"1__\" for ship, \"0__\" for no ship)\n",
    "    label = int(os.path.basename(image_path).split(\"__\")[0])\n",
    "    labels.append(label)\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    image_array = np.array(image, dtype=np.float32) / 255.0\n",
    "    images.append(image_array)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 78, 78, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 39, 39, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 37, 37, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 18, 18, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1048640   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1105025 (4.22 MB)\n",
      "Trainable params: 1105025 (4.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3])),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 0.3420 - accuracy: 0.8621 - val_loss: 0.2168 - val_accuracy: 0.9078\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.1897 - accuracy: 0.9246 - val_loss: 0.2348 - val_accuracy: 0.8922\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.1665 - accuracy: 0.9297 - val_loss: 0.1956 - val_accuracy: 0.9406\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.1326 - accuracy: 0.9484 - val_loss: 0.1495 - val_accuracy: 0.9438\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.1162 - accuracy: 0.9535 - val_loss: 0.1709 - val_accuracy: 0.9359\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.1009 - accuracy: 0.9629 - val_loss: 0.1186 - val_accuracy: 0.9594\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 4s 44ms/step - loss: 0.0641 - accuracy: 0.9750 - val_loss: 0.1132 - val_accuracy: 0.9578\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0616 - accuracy: 0.9773 - val_loss: 0.1165 - val_accuracy: 0.9609\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 4s 45ms/step - loss: 0.0371 - accuracy: 0.9875 - val_loss: 0.1082 - val_accuracy: 0.9750\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 4s 46ms/step - loss: 0.0335 - accuracy: 0.9887 - val_loss: 0.1192 - val_accuracy: 0.9625\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=10, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 13ms/step - loss: 0.0945 - accuracy: 0.9663\n",
      "Test accuracy: 0.9662500023841858\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDT4173-MPC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
